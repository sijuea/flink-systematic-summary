

### **1. 概念**  
*   **核心定义**：  
    Flink 执行模型是**将逻辑数据流图（Logical Dataflow Graph）转化为分布式物理执行计划**的过程
*   **关键组件**：  
    - **JobGraph**：优化后的逻辑图（算子链合并）  
    - **ExecutionGraph**：并行化的物理图（拆分子任务）  
    - **物理执行单元**：Task（线程）、Slot（资源单元）、TaskManager（JVM进程）  

---

### **2. 原理**  
*   **数据流驱动**：  
    采用 **Pipelined 数据交换**模式，上游产出数据立即推给下游（非批处理阻塞），实现低延迟
*   **并行度（Parallelism）**：  
    每个算子被拆分为多个 **SubTask**，独立处理数据分
*   **算子链优化（Operator Chaining）**：  
    将相邻算子融合为单个 **Task**（同一线程），减少序列化/网络开销

---

### **3. 实现**  
*   **执行流程**：  
    1. **Client** 提交 JobGraph 到 **JobManager**  
    2. **JobManager** 生成 ExecutionGraph，向 **ResourceManager** 申请 Slot  
    3. **TaskManager** 分配 Slot 启动 **Task**（SubTask 实例）  
    4. Task 间通过 **Netty 网络栈**进行 Pipelined 数据传输
*   **资源隔离**：  
    - **Slot**：最小资源单元，可共享（默认）或独占
    - **Managed Memory**：由 Flink 统一管理，用于排序/状态存储  

---

### **4. 场景**  
*   **高吞吐场景**：  
    增加并行度 + 开启算子链（如 Kafka→Map→Sink 链路合并）。  
*   **资源隔离需求**：  
    关键算子（如大状态窗口）配置 **Slot 共享组隔离**
*   **批流混合集群**：  
    同一 TaskManager 同时运行流/批作业，通过 Slot 划分资源。  

---

### **5. 常见问题**  
- **Q：状态过大导致性能问题**：
    > **A**：
    > 错误使用 keyed state 或 window，造成状态堆积。
    > 优化状态 TTL，定期清理过期状态。
- **Q：数据背压问题**：
    > **A** 上游生产速度大于下游消费，导致缓冲区满。
    > 可使用 backpressure 检测工具分析瓶颈。
*   **Q：如何确定并行度？**  
    > **A**：需平衡资源与延迟，Source 并行度受分区数限制，状态算子需考虑负载均衡
